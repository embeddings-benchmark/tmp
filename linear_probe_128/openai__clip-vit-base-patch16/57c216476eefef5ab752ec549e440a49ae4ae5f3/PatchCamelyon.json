{
  "dataset_revision": "502695fe1a141108650e3c5b91c8b5e0ff84ed49",
  "evaluation_time": 118.38319396972656,
  "kg_co2_emissions": 0.005626410790816666,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.78426513671875,
        "ap": 0.732103095321136,
        "ap_weighted": 0.732103095321136,
        "f1": 0.7834794403162906,
        "f1_weighted": 0.7834841705751524,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.78426513671875,
        "scores_per_experiment": [
          {
            "accuracy": 0.78387451171875,
            "ap": 0.7331230400813081,
            "ap_weighted": 0.7331230400813081,
            "f1": 0.7831111508815529,
            "f1_weighted": 0.7831166483361418
          },
          {
            "accuracy": 0.787841796875,
            "ap": 0.725544631195266,
            "ap_weighted": 0.725544631195266,
            "f1": 0.7878335737455683,
            "f1_weighted": 0.7878330094131563
          },
          {
            "accuracy": 0.780853271484375,
            "ap": 0.7349998824962302,
            "ap_weighted": 0.7349998824962302,
            "f1": 0.779290865223685,
            "f1_weighted": 0.7792987990966083
          },
          {
            "accuracy": 0.78997802734375,
            "ap": 0.7363536193426282,
            "ap_weighted": 0.7363536193426282,
            "f1": 0.7896241158870934,
            "f1_weighted": 0.7896278024647669
          },
          {
            "accuracy": 0.778778076171875,
            "ap": 0.7304943034902482,
            "ap_weighted": 0.7304943034902482,
            "f1": 0.7775374958435535,
            "f1_weighted": 0.7775445935650886
          }
        ]
      }
    ]
  },
  "task_name": "PatchCamelyon"
}