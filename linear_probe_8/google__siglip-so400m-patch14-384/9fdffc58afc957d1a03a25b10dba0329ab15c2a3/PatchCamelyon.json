{
  "dataset_revision": "502695fe1a141108650e3c5b91c8b5e0ff84ed49",
  "evaluation_time": 740.1431128978729,
  "kg_co2_emissions": 0.05894628319299485,
  "mteb_version": "1.14.15",
  "scores": {
    "test": [
      {
        "accuracy": 0.6868896484375,
        "ap": 0.6231381559225463,
        "ap_weighted": 0.6231381559225463,
        "f1": 0.6814127952636606,
        "f1_weighted": 0.6813973439299413,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6868896484375,
        "scores_per_experiment": [
          {
            "accuracy": 0.651397705078125,
            "ap": 0.5924005743326188,
            "ap_weighted": 0.5924005743326188,
            "f1": 0.6397462123659261,
            "f1_weighted": 0.6397185319148875
          },
          {
            "accuracy": 0.71881103515625,
            "ap": 0.6556919014847161,
            "ap_weighted": 0.6556919014847161,
            "f1": 0.7187486567349262,
            "f1_weighted": 0.7187468671900521
          },
          {
            "accuracy": 0.68011474609375,
            "ap": 0.6187474031077224,
            "ap_weighted": 0.6187474031077224,
            "f1": 0.6788944910104564,
            "f1_weighted": 0.6788860337970078
          },
          {
            "accuracy": 0.685546875,
            "ap": 0.6209834651093026,
            "ap_weighted": 0.6209834651093026,
            "f1": 0.6819430980182214,
            "f1_weighted": 0.6819286333170331
          },
          {
            "accuracy": 0.698577880859375,
            "ap": 0.6278674355783718,
            "ap_weighted": 0.6278674355783718,
            "f1": 0.6877315181887727,
            "f1_weighted": 0.6877066534307263
          }
        ]
      }
    ]
  },
  "task_name": "PatchCamelyon"
}